{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4030068b-5bf4-4113-8fa9-9d0429bf344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    v2 文本特征挖掘\n",
    "    tf-idf\n",
    "    \n",
    "    提取字段的个数 count()\n",
    "    唯一值的个数 \n",
    "    LightGBM = 0.72\n",
    "    XGBoost = 0.68\n",
    "    \n",
    "    0.3 * lgb + 0.7 xgb\n",
    "    mrege = 0.688 反而下降了\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "with open('./datasets/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('./datasets/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2a6197-84b8-4297-9797-396a629900d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apis(df):\n",
    "    group_fileid = df.groupby('file_id')\n",
    "    file_api = {}\n",
    "    for file_id, file_group in group_fileid:\n",
    "        result = file_group.sort_values(['tid', 'index'], ascending=True)\n",
    "        api_sequence  = ' '.join(result['api'])\n",
    "        file_api[file_id] = api_sequence\n",
    "    return file_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e57266c-c468-4feb-8aee-e41146644ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 881 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "if Path('./datasets/train_apis.pkl').exists():\n",
    "    with open('./datasets/train_apis.pkl', 'rb') as f:\n",
    "        train_apis = pickle.load(f)\n",
    "else:\n",
    "    # file_id 对应的api调用序列\n",
    "    train_apis = get_apis(train)\n",
    "    with open('./datasets/train_apis.pkl', 'wb') as f:\n",
    "        pickle.dump(train_apis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ca4897-9083-4de6-a5ea-4f9cb80bd263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 798 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "if Path('./datasets/test_apis.pkl').exists():\n",
    "    with open('./datasets/test_apis.pkl', 'rb') as f:\n",
    "        test_apis = pickle.load(f)\n",
    "else:\n",
    "    # file_id 对应的api调用序列\n",
    "    test_apis = get_apis(test)\n",
    "    with open('./datasets/test_apis.pkl', 'wb') as f:\n",
    "        pickle.dump(test_apis, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dbc9b40-f122-4e8c-8647-b129eedfb488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13887"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83bb3a2-fec2-4986-a1b7-e85208b843bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270a9ae3-527c-4b8d-ae29-a7565960868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造新特征\n",
    "\n",
    "def get_feature(df):\n",
    "    df_file = df.groupby('file_id')\n",
    "    if 'label' in df.columns:\n",
    "        df1 = df.drop_duplicates(subset = ['file_id', 'label'], keep='first')\n",
    "    else:\n",
    "        df1 = df.drop_duplicates(subset = ['file_id'], keep='first')\n",
    "    df1 = df1.sort_values('file_id')\n",
    "    \n",
    "    # 提取多个特征 统计特征\n",
    "    features = ['tid', 'index']\n",
    "    for f in features:\n",
    "        df1[f + '_count'] = df_file[f].count().values\n",
    "        df1[f + '_nuinque'] = df_file[f].nunique().values\n",
    "        df1[f + '_min'] = df_file[f].min().values\n",
    "        df1[f + '_max'] = df_file[f].max().values\n",
    "        df1[f + '_median'] = df_file[f].median().values\n",
    "        df1[f + '_std'] = df_file[f].std().values\n",
    "    return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e5de5-14f6-4dbd-86c9-aa8c1900c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "if Path('./datasets/df_train.pkl').exists():\n",
    "    with open('./datasets/df_train.pkl', 'rb') as f:\n",
    "        df_train = pickle.load(f)\n",
    "else:\n",
    "    # file_id 对应的api调用序列\n",
    "    df_train = get_feature(train)\n",
    "    with open('./datasets/df_train.pkl', 'wb') as f:\n",
    "        pickle.dump(df_train, f)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9abc6-e062-447e-934e-5df6736fb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pathlib import Path\n",
    "if Path('./datasets/df_test.pkl').exists():\n",
    "    with open('./datasets/df_test.pkl', 'rb') as f:\n",
    "        df_test = pickle.load(f)\n",
    "else:\n",
    "    # file_id 对应的api调用序列\n",
    "    df_test = get_feature(test)\n",
    "    with open('./datasets/df_test.pkl', 'wb') as f:\n",
    "        pickle.dump(df_test, f)\n",
    "\n",
    "df_test\n",
    "df_test = get_feature(test)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f0c52-a81c-46cc-bc90-582a20d5ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40313f-9913-4c50-98f4-bfbda34e8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame.from_dict(train_apis, orient='index', columns=['api'])\n",
    "temp = temp.reset_index().rename(columns={'index': 'file_id'})\n",
    "df_train = df_train.merge(temp, on='file_id', how=\"left\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce9c24-d7eb-4136-8905-0d1da67ec397",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame.from_dict(test_apis, orient='index', columns=['api'])\n",
    "temp = temp.reset_index().rename(columns={'index': 'file_id'})\n",
    "df_test = df_test.merge(temp, on='file_id', how=\"left\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c7bce-f919-4308-b6fa-8dcf956e3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('./df_train.pkl')\n",
    "df_test.to_pickle('./df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937648d3-e182-4348-ac46-981d78608535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,3), min_df = 0.1, max_df = 0.8)\n",
    "\n",
    "df_all = pd.concat([train, test])\n",
    "api_features = vec.fit_transform(df_all['api'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea8af6-a6f2-4731-bda6-f6b52b343573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apis = pd.DataFrame(api_features.toarray(), columns = vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b444ede-6f6f-4d5c-8828-8bf6a765b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apis.to_pickle('./df_apis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf48d-925e-47eb-a461-87530d303c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_apis = df_apis[df_train.index < 13886]\n",
    "df_train_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d48aa7-f8a2-4328-95db-d1e126504ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_apis = df_apis[df_test.index < 13886]\n",
    "# df_test_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b275b-f642-499a-8e24-dfd22b553647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_train_apis, left_index = True, right_index = True)\n",
    "df_test = df_test.merge(df_test_apis, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe52d0-4fb1-4404-8f16-63383da973b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('./df_train2.pkl')\n",
    "df_test.to_pickle9('./df_test2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c05dd-8172-4466-bcd4-6e8b76e70231",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'api' in df_train.columns:\n",
    "    df_train.drop(['api'], axis = 1, inplace = True)\n",
    "if 'api' in df_test.columns:\n",
    "    df_test.drop(['api'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578c185-ee73-43eb-8f39-bc5c1d7092ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246da528-93ff-4c73-a471-4432a7607875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.72\n",
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    num_leaves=2**5 - 1, reg_alpha=0.25, reg_lambda= 0.25, objective='multiclass', max_depth=-1, learning_rate=0.005, min_child_samples=3,\n",
    "    random_state=2021, n_estimators=10000, subsample=1, colsample_bytree=1\n",
    ")\n",
    "\n",
    "clf.fit(df_train.drop('label', axis=1), df_train['label'])\n",
    "\n",
    "# result = ensemble_model(clf, features, labels, test_fea, cate_features)\n",
    "result = clf.predict_proba(df_test)\n",
    "result = pd.DataFrame(result, columns = ['prob0', 'prob1','prob2','prob3','prob4','prob5','prob6','prob7'])\n",
    "result['file_id'] = df_test['file_id'].values\n",
    "columns = ['file_id', 'prob0', 'prob1','prob2','prob3','prob4','prob5','prob6','prob7']\n",
    "result.to_csv('v2 lgb nl25 ne10000.csv', index = False, columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906b48-9ddb-47b2-bb5d-1b34fa846334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # 0.683331\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# model_xgb = xgb.XGBClassifier(\n",
    "#     max_depth=9, learning_rate=0.005, n_estimators=2000, \n",
    "#     objective='multi:softprob', tree_method='gpu_hist', \n",
    "#     subsample=0.8, colsample_bytree=0.8, \n",
    "#     min_child_samples=3, eval_metric='logloss', reg_lambda=0.5\n",
    "# )\n",
    "\n",
    "\n",
    "# model_xgb = model_xgb.fit(df_train.drop('label', axis=1), df_train['label'])\n",
    "\n",
    "# # result = ensemble_model(clf, features, labels, test_fea, cate_features)\n",
    "# result = model_xgb.predict_proba(df_test)\n",
    "# result = pd.DataFrame(result, columns = ['prob0', 'prob1','prob2','prob3','prob4','prob5','prob6','prob7'])\n",
    "# result['file_id'] = df_test['file_id'].values\n",
    "# columns = ['file_id', 'prob0', 'prob1','prob2','prob3','prob4','prob5','prob6','prob7']\n",
    "# result.to_csv('v1 xgb.csv', index = False, columns = columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84d837-a006-4d10-b628-cedc8d140b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
