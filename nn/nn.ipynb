{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "# digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< Updated upstream
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签为: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "<matplotlib.image.AxesImage at 0x7fa2b637ca90>"
      ]
     },
     "execution_count": 4,
=======
       "<matplotlib.image.AxesImage at 0x1b2c300f580>"
      ]
     },
     "execution_count": 2,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKtklEQVR4nO3dXYhc9RnH8d+vq9L6EoxNKJINXRckIIWauAQkIDR2S6yivaiSgEKl4E0VpQWjveud3oi9KIJErWCqZKOCiNUKKq3QWneS2BpXSxJTMlWbhEZ8KTREn17sBKJd3TNnzts+/X5gcV+G/T/D5uuZmT17/o4IAcjjK20PAKBaRA0kQ9RAMkQNJEPUQDKn1fFNV6xYERMTE3V861YdO3as0fX6/X5jay1btqyxtcbHxxtba2xsrLG1mnTw4EEdPXrUC32tlqgnJiY0Oztbx7du1czMTKPrbd26tbG1pqenG1vrrrvuamyt5cuXN7ZWk6ampr7wazz8BpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSKRS17U2237K9z/YddQ8FoLxFo7Y9JulXkq6QdJGkLbYvqnswAOUUOVKvl7QvIg5ExHFJj0m6pt6xAJRVJOpVkg6d8nF/8LnPsH2T7Vnbs0eOHKlqPgBDKhL1Qn/e9T9XK4yI+yNiKiKmVq5cOfpkAEopEnVf0upTPh6X9E494wAYVZGoX5V0oe0LbJ8habOkp+odC0BZi14kISJO2L5Z0nOSxiQ9GBF7a58MQCmFrnwSEc9IeqbmWQBUgDPKgGSIGkiGqIFkiBpIhqiBZIgaSIaogWRq2aEjqyZ3zJCkt99+u7G1mtxS6LzzzmtsrR07djS2liRde+21ja63EI7UQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kU2SHjgdtH7b9ehMDARhNkSP1ryVtqnkOABVZNOqI+L2kfzUwC4AKVPacmm13gG6oLGq23QG6gVe/gWSIGkimyK+0HpX0R0lrbPdt/7j+sQCUVWQvrS1NDAKgGjz8BpIhaiAZogaSIWogGaIGkiFqIBmiBpJZ8tvu9Hq9xtZqchscSdq/f39ja01OTja21vT0dGNrNfnvQ2LbHQA1IGogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJki1yhbbftF23O299q+tYnBAJRT5NzvE5J+FhG7bJ8jqWf7+Yh4o+bZAJRQZNuddyNi1+D9DyXNSVpV92AAyhnqObXtCUlrJb2ywNfYdgfogMJR2z5b0uOSbouIDz7/dbbdAbqhUNS2T9d80Nsj4ol6RwIwiiKvflvSA5LmIuKe+kcCMIoiR+oNkm6QtNH2nsHb92ueC0BJRbbdeVmSG5gFQAU4owxIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZJb8XlrHjh1rbK1169Y1tpbU7P5WTbrkkkvaHiE1jtRAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJFLjz4Vdt/tv3aYNudXzQxGIByipwm+h9JGyPio8Glgl+2/duI+FPNswEoociFB0PSR4MPTx+8RZ1DASiv6MX8x2zvkXRY0vMRwbY7QEcVijoiPomIiyWNS1pv+1sL3IZtd4AOGOrV74h4X9JLkjbVMQyA0RV59Xul7XMH739N0nclvVnzXABKKvLq9/mSHrY9pvn/CeyIiKfrHQtAWUVe/f6L5vekBrAEcEYZkAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8mw7c4QpqenG1srsyZ/ZsuXL29sra7gSA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKFox5c0H+3bS46CHTYMEfqWyXN1TUIgGoU3XZnXNKVkrbVOw6AURU9Ut8r6XZJn37RDdhLC+iGIjt0XCXpcET0vux27KUFdEORI/UGSVfbPijpMUkbbT9S61QASls06oi4MyLGI2JC0mZJL0TE9bVPBqAUfk8NJDPU5Ywi4iXNb2ULoKM4UgPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJLPltd5rcVqXX+9LT35e0JrfCmZ2dbWyt6667rrG1uoIjNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRQ6TXRwJdEPJX0i6URETNU5FIDyhjn3+zsRcbS2SQBUgoffQDJFow5Jv7Pds33TQjdg2x2gG4pGvSEi1km6QtJPbF/2+Ruw7Q7QDYWijoh3Bv89LOlJSevrHApAeUU2yDvL9jkn35f0PUmv1z0YgHKKvPr9DUlP2j55+99ExLO1TgWgtEWjjogDkr7dwCwAKsCvtIBkiBpIhqiBZIgaSIaogWSIGkiGqIFklvy2O5OTk42t1eR2MZI0MzOTcq0mbd26te0RGseRGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZApFbftc2zttv2l7zvaldQ8GoJyi537/UtKzEfFD22dIOrPGmQCMYNGobS+TdJmkH0lSRByXdLzesQCUVeTh96SkI5Iesr3b9rbB9b8/g213gG4oEvVpktZJui8i1kr6WNIdn78R2+4A3VAk6r6kfkS8Mvh4p+YjB9BBi0YdEe9JOmR7zeBTl0t6o9apAJRW9NXvWyRtH7zyfUDSjfWNBGAUhaKOiD2SpuodBUAVOKMMSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWTYS2sId999d2NrSc3uAzU11dy5Rb1er7G1/h9xpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGklk0attrbO855e0D27c1MBuAEhY9TTQi3pJ0sSTZHpP0D0lP1jsWgLKGffh9uaT9EfH3OoYBMLpho94s6dGFvsC2O0A3FI56cM3vqyXNLPR1tt0BumGYI/UVknZFxD/rGgbA6IaJeou+4KE3gO4oFLXtMyVNS3qi3nEAjKrotjv/lvT1mmcBUAHOKAOSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGUdE9d/UPiJp2D/PXCHpaOXDdEPW+8b9as83I2LBv5yqJeoybM9GRHMbOjUo633jfnUTD7+BZIgaSKZLUd/f9gA1ynrfuF8d1Jnn1ACq0aUjNYAKEDWQTCeitr3J9lu299m+o+15qmB7te0Xbc/Z3mv71rZnqpLtMdu7bT/d9ixVsn2u7Z223xz87C5te6Zhtf6cerBBwN80f7mkvqRXJW2JiDdaHWxEts+XdH5E7LJ9jqSepB8s9ft1ku2fSpqStCwirmp7nqrYfljSHyJi2+AKumdGxPstjzWULhyp10vaFxEHIuK4pMckXdPyTCOLiHcjYtfg/Q8lzUla1e5U1bA9LulKSdvanqVKtpdJukzSA5IUEceXWtBSN6JeJenQKR/3leQf/0m2JyStlfRKy6NU5V5Jt0v6tOU5qjYp6YikhwZPLbbZPqvtoYbVhai9wOfS/J7N9tmSHpd0W0R80PY8o7J9laTDEdFre5YanCZpnaT7ImKtpI8lLbnXeLoQdV/S6lM+Hpf0TkuzVMr26ZoPentEZLm88gZJV9s+qPmnShttP9LuSJXpS+pHxMlHVDs1H/mS0oWoX5V0oe0LBi9MbJb0VMszjcy2Nf/cbC4i7ml7nqpExJ0RMR4RE5r/Wb0QEde3PFYlIuI9SYdsrxl86nJJS+6FzULX/a5TRJywfbOk5ySNSXowIva2PFYVNki6QdJfbe8ZfO7nEfFMeyOhgFskbR8cYA5IurHleYbW+q+0AFSrCw+/AVSIqIFkiBpIhqiBZIgaSIaogWSIGkjmv+vysde9kE/IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image1 = digits.images[0]\n",
    "print(\"标签为:\", digits.target[0])\n",
    "plt.imshow(image1, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullyConnect:\n",
    "    def __init__(self, l_x, l_y):  # 两个参数分别为输入层的长度和输出层的长度\n",
    "        # 使用随机数初始化参数，请暂时忽略这里为什么多了np.sqrt(l_x)\n",
    "        self.weights = np.random.randn(l_y, l_x) / np.sqrt(l_x)\n",
    "        self.bias = np.random.randn(l_y, 1)  # 使用随机数初始化参数\n",
    "        self.lr = 0  # 先将学习速率初始化为0，最后统一设置学习速率\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x  # 把中间结果保存下来，以备反向传播时使用\n",
    "        self.y = np.array([np.dot(self.weights, xx) +\n",
    "                           self.bias for xx in x])  # 计算全连接层的输出\n",
    "        print('FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape', np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape)\n",
    "        return self.y  # 将这一层计算的结果向前传递\n",
    "\n",
    "    def backward(self, d):\n",
    "        # 根据链式法则，将反向传递回来的导数值乘以x，得到对参数的梯度\n",
    "        ddw = [np.dot(dd, xx.T) for dd, xx in zip(d, self.x)]\n",
    "        # 每一条数据都能求出一个ddw，然后对他们取一个平均，得到平均的梯度变化\n",
    "        self.dw = np.sum(ddw, axis=0) / self.x.shape[0]\n",
    "        self.db = np.sum(d, axis=0) / self.x.shape[0]\n",
    "        self.dx = np.array([np.dot(self.weights.T, dd) for dd in d])\n",
    "\n",
    "        # 利用梯度下降的思想，更新参数。这里的lr就是步长的意思\n",
    "        self.weights -= self.lr * self.dw\n",
    "        self.bias -= self.lr * self.db\n",
    "        return self.dx  # 反向传播梯度"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "array([[[ 3.24492368]],\n",
       "\n",
       "       [[15.25275547]]])"
      ]
     },
     "execution_count": 7,
=======
       "(2, 64)"
      ]
     },
     "execution_count": 4,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0:2].shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 8,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):  # 无参数，不需初始化\n",
    "        pass\n",
    "    # 这里输入的变量的 x，其实就是上面公式的 z\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # 完成正向传播，将输入的 z ，放入 Sigmoid 函数中，最终得到结果 h，并返回\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.sigmoid(x)\n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": 6,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'g(z)')"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 9,
=======
     "execution_count": 6,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sig = Sigmoid()\n",
    "print(sig.sigmoid(0))  # 当 z=0 时，正确输出应该是 0.5\n",
    "%matplotlib inline\n",
    "z = np.linspace(-6, 6, 1000)  # 生成等间距 z 值方便绘图\n",
    "plt.plot(z, sig.sigmoid(z))\n",
    "plt.grid(1)  # 生成网格，方便观察\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"g(z)\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # 传入的参数，第一个参数为预测出来的标签值，第二个参数为实际标签值\n",
    "    def forward(self, x, label):\n",
    "        # 将真实 label 转换成独热编码\n",
    "        self.x = x\n",
    "        # 由于我们的label本身只包含一个数字，我们需要将其转换成和模型输出值尺寸相匹配的向量形式\n",
    "        self.label = np.zeros_like(x)\n",
    "        print('self.label.shape: ', self.label.shape)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0  # 只有正确标签所代表的位置概率为1，其他为 0\n",
    "        # 计算损失\n",
    "        self.loss = np.sum(np.square(x - self.label)) / \\\n",
    "            self.x.shape[0] / 2  # 求平均后再除以 2 是为了表示方便\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.label.shape:  (1, 4)\n",
      "实际为阴天和预测值为晴天的平均损失是： 1.0\n",
      "self.label.shape:  (1, 4)\n",
      "实际为雪天和预测值为晴天的平均损失是： 1.0\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "loss = QuadraticLoss()\n",
    "# 假设神经网络算出样本的预测值为0，即为晴天\n",
    "pred = np.zeros((1, 4))\n",
    "pred[0][0] = 1\n",
    "print(\"实际为阴天和预测值为晴天的平均损失是：\", loss.forward(pred, [1]))\n",
    "print(\"实际为雪天和预测值为晴天的平均损失是：\", loss.forward(pred, [2]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, label):  # 只需forward\n",
    "        self.accuracy = np.sum(\n",
    "            [np.argmax(xx) == ll for xx, ll in zip(x, label)])  # 对预测正确的实例数求和\n",
    "        self.accuracy = 1.0 * self.accuracy / x.shape[0]  # 也就是计算正确率 ,公式 7 的实现\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "loss: 18.552628863213645 accuracy: 0.0\n"
=======
      "FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape (1797, 10, 10)\n",
      "self.label.shape:  (1797, 10, 10)\n",
      "loss: 16.72930397866903 accuracy: 0.0\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# 图片大小为 8*8\n",
    "# 则此时一张图片就是一条数据，每张图片对呀一个 label（0-9范围内）\n",
    "x = digits.data\n",
    "labels = digits.target\n",
    "\n",
    "# 开始搭建神经网络\n",
    "inner_layers = []\n",
    "inner_layers.append(FullyConnect(8 * 8, 10))\n",
    "inner_layers.append(Sigmoid())\n",
    "# 神经网络搭建完成\n",
    "\n",
    "losslayer = QuadraticLoss()  # 计算损失\n",
    "accuracy = Accuracy()  # 计算准确率\n",
    "\n",
    "# 开始将数据送入神经网络进行正向传播\n",
    "for layer in inner_layers:  # 前向计算\n",
    "    x = layer.forward(x)\n",
    "\n",
    "loss = losslayer.forward(x, labels)  # 调用损失层forward函数计算损失函数值\n",
    "accu = accuracy.forward(x, labels)\n",
    "print('loss:', loss, 'accuracy:', accu)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticLoss:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # 正向传播和上文一样，具体注释参照上文\n",
    "    def forward(self, x, label):\n",
    "        self.x = x\n",
    "        self.label = np.zeros_like(x)\n",
    "        for a, b in zip(self.label, label):\n",
    "            a[b] = 1.0\n",
    "        # 对公式 8 实现\n",
    "        self.loss = np.sum(np.square(x - self.label)) / \\\n",
    "        self.x.shape[0] / 2  # 求平均后再除以2是为了表示方便\n",
    "        return self.loss\n",
    "\n",
    "    # 定义反向传播\n",
    "    def backward(self):\n",
    "        # 这里的dx，就是我们求得函数关于x偏导数，也就是梯度，将它保存起来，后面更新的时候会用到\n",
    "        self.dx = (self.x - self.label) / self.x.shape[0]  # 2被抵消掉了\n",
    "        return self.dx"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
=======
   "execution_count": 14,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):  # 无参数，不需初始化\n",
    "        pass\n",
    "    # 即公式 5\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.sigmoid(x)\n",
    "        return self.y\n",
    "    # 即公式 9\n",
    "    def backward(self, d):\n",
    "        sig = self.sigmoid(self.x)\n",
    "        self.dx = d * sig * (1 - sig)\n",
    "        return self.dx  # 反向传递梯度"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
=======
   "execution_count": 15,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 64), (1500,), (296, 64), (296,))"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 16,
=======
     "execution_count": 15,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,train_target = digits.data[:1500],digits.target[:1500]\n",
    "test_data,test_target = digits.data[1500:-1],digits.target[1500:-1]\n",
    "train_data.shape,train_target.shape,test_data.shape,test_target.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
=======
   "execution_count": 16,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "[<__main__.FullyConnect at 0x7fa2b6541ee0>,\n",
       " <__main__.Sigmoid at 0x7fa2b4354400>,\n",
       " <__main__.FullyConnect at 0x7fa2b65417f0>,\n",
       " <__main__.Sigmoid at 0x7fa2b4354460>]"
      ]
     },
     "execution_count": 17,
=======
       "[<__main__.FullyConnect at 0x1b2c47ced30>,\n",
       " <__main__.Sigmoid at 0x1b2c47cae20>,\n",
       " <__main__.FullyConnect at 0x1b2c47cee20>,\n",
       " <__main__.Sigmoid at 0x1b2c47cad30>]"
      ]
     },
     "execution_count": 16,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_layers = []\n",
    "inner_layers.append(FullyConnect(64, 32)) # 因为每条数据的长度为 8*8=64，因此这里第一个全连接层，接收长度为64\n",
    "inner_layers.append(Sigmoid())\n",
    "inner_layers.append(FullyConnect(32, 10))\n",
    "inner_layers.append(Sigmoid())\n",
    "inner_layers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
=======
   "execution_count": 17,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< Updated upstream
       "(<__main__.QuadraticLoss at 0x7fa2b6541be0>,\n",
       " <__main__.Accuracy at 0x7fa2b6541b20>,\n",
       " 350)"
      ]
     },
     "execution_count": 18,
=======
       "(<__main__.QuadraticLoss at 0x1b2c47ce190>,\n",
       " <__main__.Accuracy at 0x1b2c47ce6a0>,\n",
       " 1)"
      ]
     },
     "execution_count": 17,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losslayer = QuadraticLoss()\n",
    "accuracy = Accuracy()\n",
    "for layer in inner_layers:\n",
    "    layer.lr = 1000     #所有中间层设置学习速率\n",
    "epochs = 1  # 对训练数据遍历的次数，也就是学习时间。\n",
    "#在开始的时候，准确率会随之学习时间的增加而提高。\n",
    "#当模型学习完训练数据中的所有信息后，准确率就会趋于稳定\n",
    "losslayer,accuracy,epochs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FullyConnect' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s9/hchzpf8511z85g2sf7tw1zqh0000gn/T/ipykernel_18522/1689363377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minner_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FullyConnect' object has no attribute 'backward'"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape (1500, 32, 1)\n",
      "FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape (1500, 10, 1)\n",
      "FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape (296, 32, 1)\n",
      "FullyConnect np.array([np.dot(self.weights, xx) + self.bias for xx in x]).shape (296, 10, 1)\n",
      "epochs:0,loss:1.0445214318709943,test_accuracy:0.10135135135135136\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    print(i)\n",
    "    losssum = 0\n",
    "    iters = 0\n",
    "    x = train_data\n",
    "    label = train_target\n",
    "    x = x.reshape(-1,64,1)\n",
    "    for layer in inner_layers:  # 前向计算\n",
    "        x = layer.forward(x)\n",
    "    loss = losslayer.forward(x, label)  # 调用损失层forward函数计算损失函数值\n",
    "    losssum += loss\n",
    "    iters += 1\n",
    "    d = losslayer.backward()  # 调用损失层backward函数层计算将要反向传播的梯度\n",
    "\n",
    "    for layer in inner_layers[::-1]:  # 反向传播\n",
    "        d = layer.backward(d)\n",
    "\n",
    "    if i%10==0: \n",
    "        x = test_data\n",
    "        label = test_target\n",
    "        x = x.reshape(-1,64,1)\n",
    "        for layer in inner_layers:\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        accu = accuracy.forward(x, label)  # 调用准确率层forward()函数求出准确率\n",
    "        print('epochs:{},loss:{},test_accuracy:{}'.format(i,losssum / iters,accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
